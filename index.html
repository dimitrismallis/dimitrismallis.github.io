<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="lhGajE3afrJp3Jyzmt5y_513I9mjrw1rCg9KE9PQBY0">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Dr. Dimitri(o)s  Mallis</title>
    <meta name="author" content="Dr. Dimitri(o)s  Mallis">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="dimitrismallis, mallis, dimitriosmallis">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%98%95%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://dimitrismallis.github.io//">
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%6D%61%6C%6C%64%69%6D%69%31@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=Gfc5ZXoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/dimitrismallis" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/dimitrismallis" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://instagram.com/dimimall1" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fab fa-instagram"></i></a>
            

          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Vitae</a>
              </li>
<!-- Morfis link -->
              <li class="nav-item">
                <a class="nav-link" href="https://morfisai.github.io//" rel="external nofollow noopener" target="_blank">Morfis
                <span class="sr-only">(current)</span></a>
              </li>

                <!-- Photography porfolio link -->
              <li class="nav-item">
                <a class="nav-link" href="https://dimitrismallis.myportfolio.com/" rel="external nofollow noopener" target="_blank">Photography
                <span class="sr-only">(current)</span></a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Dr. Dimitri(o)s</span>  Mallis
          </h1>
          <p class="desc"><font size="2">  <b>Computer Vision Researcher</b> @ <a href="https://wwwen.uni.lu/" rel="external nofollow noopener" target="_blank">SnT</a>  â€¢  <i>PhD from the University of Nottingham.</i></font></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/profile.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="profile.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>Welcome!! ðŸ‘‹  I am a Postdoctoral Researcher at the <a href="https://www.uni.lu/snt" rel="external nofollow noopener" target="_blank">Interdisciplinary Centre for Security, Reliability and Trust (SnT)</a> of the <strong>University of Luxembourg</strong>, focusing on computer vision its appliations for Computer-Aided Design (CAD).</p>

<p>I received my PhD in Computer Vision at the <strong>University of Nottingham</strong> under the supervision of <a href="https://ytzimiro.github.io/" rel="external nofollow noopener" target="_blank">Dr. Yorgos Tzimiropoulos</a>. I was also a Research Intern at <a href="https://research.samsung.com/aicenter_cambridge" rel="external nofollow noopener" target="_blank">Samsung AI Cambridge (SAIC)</a> and later a Senior Machine Learning Engineer for <a href="https://www.taboola.com/" rel="external nofollow noopener" target="_blank">Taboola</a> and <a href="https://deeplab.ai/" rel="external nofollow noopener" target="_blank">Deeplab</a>.</p>

<p>In this website you can find more info about me, check publications and recent news. You can also browse through my photography <a href="https://dimitriosmallis.myportfolio.com/" rel="external nofollow noopener" target="_blank">here</a> ðŸ“¸ !!</p>

<h3 id="research">Research</h3>

<p>During my PhD, I concentrated on learning with minimal manual supervision through self-supervised and semi-supervised learning, specifically for the tasks of landmark detection and human pose estimation. Later, I also looked into deep learning based recommender systems and the problem of click-through-rate (CTR) prediction.</p>

<p>Currently my focus in on 3D vision and itâ€™s application towards accelerating parametric Computer-Aided Design (CAD). I am particularly interested in automated reverse engineering of 2D/3D CAD models as well as Multimodal Large Language Models (MLLMs) for AI-assisted design. I also lead <a href="https://morfisai.github.io/" rel="external nofollow noopener" target="_blank">Morfis</a>, an SnT project focused on AI-assisted physical product customization.</p>


          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: inherit;">News</a></h2></article>          <div class="news">
            <div class="table-responsive" style="max-height: 60vw">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row"><abbr class="badge" style="background-color: black;">Aug 27, 2025 </abbr></th>
                  <td>
                    ðŸš¨ Paper Announcement: Two papers accepted at ICCV 2025! ðŸŽ‰ Weâ€™re thrilled to share that <a href="https://cadassistant.github.io/" rel="external nofollow noopener" target="_blank">CAD-Assistant</a> and <a href="https://cad-recode.github.io/" rel="external nofollow noopener" target="_blank">CAD-Recode</a>, our two recent papers on AI for Computer Aided Design (CAD) that are accepted at <a href="https://iccv.thecvf.com/" rel="external nofollow noopener" target="_blank">ICCV 2025</a> ðŸš€.

                  </td>
                </tr>
                <tr>
                  <th scope="row"><abbr class="badge" style="background-color: black;">Jun 10, 2025 </abbr></th>
                  <td>
                    ðŸš€ Morfis at CVPR 2025. The <a href="https://www.morfis.ai/" rel="external nofollow noopener" target="_blank">Morfis Platform</a> for AI-Assisted Physical Product Customization will be showcased at CVPR 2025 demo session.

                  </td>
                </tr>
                <tr>
                  <th scope="row"><abbr class="badge" style="background-color: black;">Feb 03, 2025 </abbr></th>
                  <td>
                    Very exciting news, the <a href="https://morfisai.github.io/" rel="external nofollow noopener" target="_blank">Morfis</a> project has been selected to be part of this years cohort of the <a href="https://www.uni.lu/snt-en/innovation/" rel="external nofollow noopener" target="_blank">Venture Program</a> of SnT. Check out the project video <a href="https://www.youtube.com/watch?v=mfhrHtmdkb4&amp;ab_channel=Morfis" rel="external nofollow noopener" target="_blank">here</a> ðŸŽ¥!

                  </td>
                </tr>
              </table>
            </div>
          </div>


          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <h2>Selected Publications <a href="/publications/">[View All]</a>
</h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2"><div class="preview">
              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cadassistant-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cadassistant-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cadassistant-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/cadassistant.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cadassistant.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div></div>

        <!-- Entry bib key -->
        <div id="Mallis2025CADAssistant" class="col-sm-8">
        <!-- Title -->
        <div class="title"><a href="https://cadassistant.github.io/" style="color: black;" rel="external nofollow noopener" target="_blank"> CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers </a></div>
        <!-- Author -->
        <div class="author">
        

        <em>Dimitrios Mallis</em>,Â Ahmet Serdar Karadeniz,Â Sebastian Cavada,Â Danila Rukhovich,Â Niki Foteinopoulou,Â Kseniya Cherenkova,Â Anis Kacem,Â andÂ Djamila Aouada</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Conference on Computer Vision (ICCV)</em>, 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2412.13810" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://cadassistant.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
            <a href="https://github.com/dimitrismallis/CAD-Assistant" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Mallis2025CADAssistant</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mallis, Dimitrios and Karadeniz, Ahmet Serdar and Cavada, Sebastian and Rukhovich, Danila and Foteinopoulou, Niki and Cherenkova, Kseniya and Kacem, Anis and Aouada, Djamila}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=GdiaQQVE9bI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2"><div class="preview">
              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cadrecode-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cadrecode-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cadrecode-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/cadrecode.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cadrecode.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div></div>

        <!-- Entry bib key -->
        <div id="Rukhovich2025CADRecodeRE" class="col-sm-8">
        <!-- Title -->
        <div class="title"><a href="https://cad-recode.github.io/" style="color: black;" rel="external nofollow noopener" target="_blank"> CAD-Recode: Reverse Engineering CAD Code from Point Clouds </a></div>
        <!-- Author -->
        <div class="author">
        

        Danila Rukhovich,Â Elona Dupont,Â <em>Dimitrios Mallis</em>,Â Kseniya Cherenkova,Â Anis Kacem,Â andÂ Djamila Aouada</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Conference on Computer Vision (ICCV)</em>, 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2412.14042" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://cad-recode.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
            <a href="https://github.com/filaPro/cad-recode" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex">  <span class="c">author = {Rukhovich, Danila and Dupont, Elona and Mallis, Dimitrios and Cherenkova, Kseniya and Kacem, Anis and Aouada, Djamila},</span>
  <span class="c">journal = {International Conference on Computer Vision (ICCV)},</span>
  <span class="c">year = {2025},</span>
<span class="c">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2"><div class="preview">
              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/davinci-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/davinci-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/davinci-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/davinci.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="davinci.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div></div>

        <!-- Entry bib key -->
        <div id="Karadeniz2024PICASSOAF" class="col-sm-8">
        <!-- Title -->
        <div class="title"><a href="https://cvi2snt.github.io/davinci/" style="color: black;" rel="external nofollow noopener" target="_blank"> DAVINCI: A Single-Stage Architecture for Constrained CAD Sketch Inference </a></div>
        <!-- Author -->
        <div class="author">
        

        Ahmet Serdar Karadeniz,Â <em>Dimitrios Mallis</em>,Â Nesryne Mejri,Â Kseniya Cherenkova,Â Anis Kacem,Â andÂ Djamila Aouada</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>British Machine Vision Conference (BMVC)</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2410.22857" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://cvi2snt.github.io/davinci/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
            <a href="https://github.com/cvi2snt/CPTSketchGraphs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This work presents DAVINCI, a unified architecture for single-stage Computer-Aided Design (CAD) sketch parameterization and constraint inference directly from raster sketch images. By jointly learning both outputs, DAVINCI minimizes error accumulation and enhances the performance of constrained CAD sketch inference. Notably, DAVINCI achieves state-of-the-art results on the large-scale SketchGraphs dataset, demonstrating effectiveness on both precise and hand-drawn raster CAD sketches. To reduce DAVINCIâ€™s reliance on large-scale annotated datasets, we explore the efficacy of CAD sketch augmentations. We introduce Constraint-Preserving Transformations (CPTs), i.e. random permutations of the parametric primitives of a CAD sketch that preserve its constraints. This data augmentation strategy allows DAVINCI to achieve reasonable performance when trained with only 0.1% of the SketchGraphs dataset. Furthermore, this work contributes a new version of SketchGraphs, augmented with CPTs. The newly introduced CPTSketchGraphs dataset includes 80 million CPT-augmented sketches, thus providing a rich resource for future research in the CAD sketch domain.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Karadeniz2024PICASSOAF</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DAVINCI: A Single-Stage Architecture for Constrained CAD Sketch Inference}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Karadeniz, Ahmet Serdar and Mallis, Dimitrios and Mejri, Nesryne and Cherenkova, Kseniya and Kacem, Anis and Aouada, Djamila}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{British Machine Vision Conference (BMVC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2"><div class="preview">
              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/TPAMI2023_preview-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/TPAMI2023_preview-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/TPAMI2023_preview-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/TPAMI2023_preview.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="TPAMI2023_preview.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div></div>

        <!-- Entry bib key -->
        <div id="Mallis2023landm" class="col-sm-8">
        <!-- Title -->
        <div class="title"><a href="https://ieeexplore.ieee.org/document/10005822" style="color: black;" rel="external nofollow noopener" target="_blank"> From Keypoints to Object Landmarks via Self-Training Correspondence: A novel approach to Unsupervised Landmark Discovery </a></div>
        <!-- Author -->
        <div class="author">
        

        <em>Dimitrios Mallis</em>,Â Enrique Sanchez,Â Matt Bell,Â andÂ Georgios Tzimiropoulos</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2205.15895" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/document/10005822" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
            <a href="https://github.com/dimitrismallis/KeypointsToLandmarks" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper proposes a novel paradigm for the unsupervised learning of object landmark detectors. Contrary to existing methods that build on auxiliary tasks such as image generation or equivariance, we propose a self-training approach where, departing from generic keypoints, a landmark detector and descriptor is trained to improve itself, tuning the keypoints into distinctive landmarks. To this end, we propose an iterative algorithm that alternates between producing new pseudo-labels through feature clustering and learning distinctive features for each pseudo-class through contrastive learning. With a shared backbone for the landmark detector and descriptor, the keypoint locations progressively converge to stable landmarks, filtering those less stable. Compared to previous works, our approach can learn points that are more flexible in terms of capturing large viewpoint changes. We validate our method on a variety of difficult datasets, including LS3D, BBCPose, Human3.6M and PennAction, achieving new state of the art results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Mallis2023landm</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mallis, Dimitrios and Sanchez, Enrique and Bell, Matt and Tzimiropoulos, Georgios}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From Keypoints to Object Landmarks via Self-Training Correspondence: A novel approach to Unsupervised Landmark Discovery}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2"><div class="preview">
              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/NEURIPS2020_preview-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/NEURIPS2020_preview-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/NEURIPS2020_preview-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/NEURIPS2020_preview.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="NEURIPS2020_preview.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div></div>

        <!-- Entry bib key -->
        <div id="unsupervLandm2020" class="col-sm-8">
        <!-- Title -->
        <div class="title"><a href="https://proceedings.neurips.cc/paper/2020/hash/32508f53f24c46f685870a075eaaa29c-Abstract.html" style="color: black;" rel="external nofollow noopener" target="_blank"> Unsupervised Learning of Object Landmarks via Self-Training Correspondence </a></div>
        <!-- Author -->
        <div class="author">
        

        <em>Dimitrios Mallis</em>,Â Enrique Sanchez,Â Matt Bell,Â andÂ Georgios Tzimiropoulos</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Neural Information Processing Systems</em>, 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://proceedings.neurips.cc/paper/2020/hash/32508f53f24c46f685870a075eaaa29c-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
            <a href="https://proceedings.neurips.cc/paper/2020/file/32508f53f24c46f685870a075eaaa29c-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/32508f53f24c46f685870a075eaaa29c-Supplemental.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a>
            <a href="https://github.com/dimitrismallis/UnsupervisedLandmarks" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper addresses the problem of unsupervised discovery of object landmarks.
We take a different path compared to existing works, based on 2 novel perspectives: <b>(1) Self-training</b>: starting from generic keypoints, we propose a self-training
approach where the goal is to learn a detector that improves itself, becoming
more and more tuned to object landmarks. <b>(2) Correspondence</b>: we identify correspondence as a key objective for unsupervised landmark discovery and propose
an optimization scheme which alternates between recovering object landmark
correspondence across different images via clustering and learning an object landmark descriptor without labels. Compared to previous works, our approach can
learn landmarks that are more flexible in terms of capturing large changes in
viewpoint. We show the favourable properties of our method on a variety of difficult datasets including LS3D, BBCPose and Human3.6M.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">unsupervLandm2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unsupervised Learning of Object Landmarks via Self-Training Correspondence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mallis, Dimitrios and Sanchez, Enrique and Bell, Matt and Tzimiropoulos, Georgios}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>


          <h2><a style="color: inherit;">Open Source Projects</a></h2>
          <!-- code for GitHub repositories -->
          
          <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center">
            
              



<div class="repo p-2 text-center">
  <a href="https://github.com/dimitrismallis/CAD-Assistant" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="dimitrismallis/CAD-Assistant" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=CAD-Assistant&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="dimitrismallis/CAD-Assistant" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=CAD-Assistant&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

            
              



<div class="repo p-2 text-center">
  <a href="https://github.com/filaPro/cad-recode" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="filaPro/cad-recode" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=filaPro&amp;repo=cad-recode&amp;theme=default&amp;show_owner=true">
    <img class="repo-img-dark w-100" alt="filaPro/cad-recode" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=filaPro&amp;repo=cad-recode&amp;theme=dark&amp;show_owner=true">
  </a>
</div>

            
              



<div class="repo p-2 text-center">
  <a href="https://github.com/dimitrismallis/KeypointsToLandmarks" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="dimitrismallis/KeypointsToLandmarks" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=KeypointsToLandmarks&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="dimitrismallis/KeypointsToLandmarks" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=KeypointsToLandmarks&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

            
              



<div class="repo p-2 text-center">
  <a href="https://github.com/dimitrismallis/UnsupervisedLandmarks" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="dimitrismallis/UnsupervisedLandmarks" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=UnsupervisedLandmarks&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="dimitrismallis/UnsupervisedLandmarks" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=dimitrismallis&amp;repo=UnsupervisedLandmarks&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

            
              



<div class="repo p-2 text-center">
  <a href="https://github.com/cvi2snt/CPTSketchGraphs" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="cvi2snt/CPTSketchGraphs" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=cvi2snt&amp;repo=CPTSketchGraphs&amp;theme=default&amp;show_owner=true">
    <img class="repo-img-dark w-100" alt="cvi2snt/CPTSketchGraphs" src="https://github-readme-stats-sigma-five.vercel.app/api/pin/?username=cvi2snt&amp;repo=CPTSketchGraphs&amp;theme=dark&amp;show_owner=true">
  </a>
</div>

            
          </div>
          


          <br><br>
          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%6D%61%6C%6C%64%69%6D%69%31@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=Gfc5ZXoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/dimitrismallis" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/dimitrismallis" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://instagram.com/dimimall1" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fab fa-instagram"></i></a>
            

              </div>

              <div class="contact-note">
                Reach out through social media or email me directly.

              </div>
            </div>
        

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2025 Dr. Dimitri(o)s  Mallis. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NDX68PFQ2J"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-NDX68PFQ2J');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
